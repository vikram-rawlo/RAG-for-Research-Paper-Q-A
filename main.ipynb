{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77180bb1-87aa-4619-9cc0-a14d4690075e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3886e21-7c17-4712-90c5-235bcb30266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain\n",
    "# !pip install langchain-openai\n",
    "# !pip install langchain-community\n",
    "# !pip install langchain-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91aecd25-0791-494d-9e92-716550cc6c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f621524c-d168-4b7f-b90d-681dbea21917",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "chroma_db_dir = os.getenv(\"CHROMA_DB_DIR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1f0192-e586-4ae0-bf55-ee2de1702b5b",
   "metadata": {},
   "source": [
    "## Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7f847f9-3590-4feb-8c64-afa9e55a91b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents loaded: 109\n"
     ]
    }
   ],
   "source": [
    "all_documents = []\n",
    "\n",
    "file_path = \"./db\"\n",
    "for file in os.listdir(file_path):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        loader = PyPDFLoader(os.path.join(file_path, file))\n",
    "        all_documents.extend(loader.load())\n",
    "\n",
    "print(f\"Total documents loaded: {len(all_documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2fd82b-2f6b-4c2a-a52f-1253b38905ec",
   "metadata": {},
   "source": [
    "## Chunking the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e55db38d-83e8-40ae-9acd-e256c359122c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7611321-f3e3-4e44-a200-ddb98c978fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to documents\n",
    "chunked_docs = text_splitter.split_documents(all_documents)\n",
    "\n",
    "# print(f\"Total chunks created: {len(chunked_docs)}\")\n",
    "# print(chunked_docs[0].page_content[:])\n",
    "# print(chunked_docs[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfe0c1e-37e2-490a-82ce-57d50499dd65",
   "metadata": {},
   "source": [
    "## Embed the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a11ff62-a644-47a9-a256-0109f903b0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize embedding model\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-3-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f08c0e6a-5fda-4791-bd6e-b53ecb71a7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save embeddings to local Chroma DB\n",
    "# vectorstore = Chroma.from_documents(\n",
    "#     documents=chunked_docs,\n",
    "#     embedding=embeddings,\n",
    "#     persist_directory=\"./chroma_db\"   # folder where Chroma stores data\n",
    "# )\n",
    "\n",
    "# # Persist to disk (so you donâ€™t have to re-embed every run)\n",
    "# vectorstore.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0995897-3fb3-431f-87f8-599865d6ef2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Collection(name=langchain)]\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "print(client.list_collections())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6507bcd0-9139-4ace-9b45-eea2febbdafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vectordb from disk\n",
    "chroma_db = Chroma(persist_directory=\"./chroma_db\",\n",
    "                   collection_name=\"langchain\",\n",
    "                  embedding_function = embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f478a20-118c-47f5-ab51-24a8b66aa7dc",
   "metadata": {},
   "source": [
    "## Semantic Similarity based Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33eb18f4-51a0-4e17-930e-8408a1723480",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_retriever = chroma_db.as_retriever(search_type=\"similarity_score_threshold\",\n",
    "                                             search_kwargs={'k':3,\"score_threshold\":0.2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8c6307-919a-4e38-8c10-5af6d805c13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what are training dataset\"\n",
    "results = similarity_retriever.get_relevant_documents(query)\n",
    "\n",
    "# for i, doc in enumerate(results, 1):\n",
    "#     print(f\"\\nResult {i}:\")\n",
    "#     print(\"Content:\", doc.page_content)\n",
    "#     print(\"Metadata:\", doc.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fca5671-6465-465a-b285-929db8311cda",
   "metadata": {},
   "source": [
    "## Generative Logic using Langchain and GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc090b1-2adc-45de-aa0c-b5069af527b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1b0bf5-5374-416b-b55c-b03bc6753307",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are a helpful assistant. Use the provided context to answer the question.\n",
    "If you can find relevant information in the context, provide an answer based on that information.\n",
    "Only if you cannot find ANY relevant information should you respond with:\n",
    "\"This tool only answers questions based on the documents in its database. Please ask something within that scope.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d434419f-dfbf-466f-8747-b2b7cd31c008",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=prompt_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2381a2ab-29e6-4e37-8a6c-f5bbdd181749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new retriever with more lenient settings for testing\n",
    "test_retriever = chroma_db.as_retriever(\n",
    "    search_type=\"similarity\", \n",
    "    search_kwargs={'k': 3}  # Remove score threshold temporarily\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046be3ce-9192-4d7d-84b7-15b1cd381004",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=test_retriever,  # Use the test retriever\n",
    "    chain_type=\"stuff\",\n",
    "    chain_type_kwargs={\"prompt\": custom_prompt},\n",
    "    return_source_documents=True,\n",
    "    verbose=True  # This will show you what's being passed to the LLM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e704238a-d6a2-4040-abd8-7ee4e9329028",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_chain({\"query\": query})\n",
    "print(\"Answer:\", result[\"result\"])\n",
    "print(\"Number of source documents:\", len(result[\"source_documents\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df4b6a7-aee1-4c4d-af76-358c8bb20b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rag-env)",
   "language": "python",
   "name": "rag-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
